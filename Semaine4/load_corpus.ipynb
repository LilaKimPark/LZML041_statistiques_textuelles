{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4221086-529f-452f-9909-2bc7a3386a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#0... Let's check your python version !\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360481e-9131-47eb-9ed9-35c951eeb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy is the fundamental package for scientific computing with Python.\n",
    "#1... Install NumPy using pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54757303-efb3-4bd9-b962-4ae74fdbb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2... Install nltk by using pip command â€“ The first step is to install nltk by using the pip command. \n",
    "#!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedf385-468e-4cb5-bbf5-50d2c3c8b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3... import the library NLKT\n",
    "# A new window should open, showing the NLTK Downloader. Click on the File menu and select Change Download Directory. \n",
    "# For central installation, set this to C:\\nltk_data (Windows), /usr/local/share/nltk_data (Mac), or /usr/share/nltk_data (Unix). \n",
    "# Next, download all.\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08bbdf-9c0e-4d40-8073-89629df3eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets explore the Guttenberg in NLKT !\n",
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227b27c-9535-4c42-a2a3-be5f2478e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk.corpus.gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081afa47-9af5-471e-a680-6067755d8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick = nltk.corpus.gutenberg.words( 'melville-moby_dick.txt')\n",
    "len(moby_dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff8ad0-881c-4b68-a714-6bd2752c0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of words in each book\n",
    "for text in nltk.corpus.gutenberg.fileids():\n",
    "    print('# of words in ',text,'is: ', len(nltk.corpus.gutenberg.words( text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be7769-7870-4ac1-847d-5d7aaaab4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load a specific book from Guttenberg website \n",
    "# you will need to leverage the requests package\n",
    "import requests\n",
    "#choose a book in Gutenberg project website the https://www.gutenberg.org/ebooks/5258 and get the reference number of the book, here 5258 !\n",
    "r = requests.get(r'https://www.gutenberg.org/cache/epub/5258/pg5258.txt')\n",
    "Zarathoustra_Nietzsche = r.text\n",
    "\n",
    "# first, remove unwanted new line and tab characters from the text\n",
    "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
    "    Zarathoustra_Nietzsche = Zarathoustra_Nietzsche.replace(char, \" \")\n",
    "#print number of characters in the book\n",
    "print(len(Zarathoustra_Nietzsche))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a4855-079d-4a48-b761-4c5b0f5fe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see the project gutenburg introduction and footnotes\n",
    "print(Zarathoustra_Nietzsche[0:910]) \n",
    "print('-------------------------------------------------') \n",
    "print(Zarathoustra_Nietzsche[637986:639986]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf318f-9596-48a4-bc88-8b549a259987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also subset for the book text\n",
    "# (removing the project gutenburg introduction/footnotes)\n",
    "Zarathoustra_Nietzsche = Zarathoustra_Nietzsche[911:635986]\n",
    "#print(Zarathoustra_Nietzsche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6bb2e-9cef-474d-88a9-259b4855345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Tokenize the Text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "\n",
    "# Choose your Text\n",
    "text = Zarathoustra_Nietzsche\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bacf1a-6405-42d9-8e1f-a7de4d127c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text, language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7d1e5-a825-4056-a56f-6f57c3e5372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 20 most commons tokens\n",
    "from collections import Counter\n",
    "print(Counter(tokens).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4964a40-68e9-49ab-bd1d-98325d12df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove punctiation !\n",
    "remove = re.sub(r'[^\\w\\s]', '', text)\n",
    "#print(\"updated text with no punctuations :\", remove)\n",
    "tokens = word_tokenize(remove, language=\"french\")\n",
    "print(Counter(tokens).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba18dd8-9682-4068-bc9a-7b61e6fa47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove Stopwords !\n",
    "french_stopwords = set(stopwords.words('french'))\n",
    "filtre_stopfr =  lambda text: [token for token in text if token.lower() not in french_stopwords]\n",
    "\n",
    "tokens_Filtered=filtre_stopfr( tokens)\n",
    "print(Counter(tokens_Filtered).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8c5f9-bfd7-4811-886f-fdb251eb424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you wantg to exclude anything else?\n",
    "Stop_words=['plus']\n",
    "for x in Stop_words:\n",
    "    french_stopwords.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17304319-021e-4b39-8451-0716ddf4209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_Filtered=filtre_stopfr( tokens)\n",
    "print(Counter(tokens_Filtered).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34488df3-4bba-47c9-ab8b-9f698e81609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmatization\n",
    "# Now it would be interesting to group words with the same syntactic root, for this we will use the stemmatization function of NLTK: stem(). 5\n",
    "stemmer=nltk.stem.snowball.FrenchStemmer()\n",
    "#stemmer = FrenchStemmer()\n",
    "\n",
    "Stemmed_Text =  lambda text: [stemmer.stem(token) for token in text]\n",
    "\n",
    "#for w in tokens_Filtered:\n",
    " #   print(stemmer.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d8fb6-0bf3-4313-aa9d-88c52196377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_stems=Stemmed_Text( tokens_Filtered)\n",
    "print(Counter(tokens_stems).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e10ec-490c-4037-8fb2-0489ca6e83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe0f6e-c49b-45c4-b4c8-75f0ed694b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "wordcloud = WordCloud(width= 1000, height = 600, max_words=100,\n",
    "                      random_state=1, background_color='White', colormap='cubehelix',\n",
    "                      collocations=False, stopwords = STOPWORDS).generate(text)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375cf20-c7ff-42b1-8ce8-3fd5b383e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae5498-d2bb-485e-b7c2-d8004ab3194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be402d9-6e2d-4a20-9d7e-91ba469aa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width= 1000, height = 600, max_words=100,\n",
    "                      random_state=1, background_color='Black', colormap='Paired',\n",
    "                      collocations=False, stopwords = stopwords).generate(text)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727ce19-7571-4a0d-abd1-a561e41821a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "folder = \"./\"\n",
    "\n",
    "data = Image.open(os.path.join(folder, \"Nietzsche.jpg\"),'r')\n",
    "#mask = np.array(Image.open(\"Nietzsche.jpg\"))\n",
    "mask = np.array(data)\n",
    "\n",
    "mask.shape\n",
    "# Generating colors from image\n",
    "image_colors = ImageColorGenerator(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e00b9-3e00-4224-bac0-75cc516ddab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width= 1000, height = 600, max_words=700,\n",
    "                      random_state=1, background_color='Yellow', colormap='winter_r',\n",
    "                      collocations=False, stopwords = stopwords, mask = mask).generate(text)\n",
    "plt.figure(figsize=(5, 13))\n",
    "plt.imshow(wordcloud) \n",
    "#plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation ='bilinear') # Using the color function here\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask) \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0cbf1-7e86-4bd1-9797-97e9fc9d4f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5def9-4d77-4471-aeb8-b5b667158097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
